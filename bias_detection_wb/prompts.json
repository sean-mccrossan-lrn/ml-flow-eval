{
  "bias_analysis": {
      "prompt": "You are an AI language model designed to detect bias in assessment questions. Please analyze the following question and provide a JSON object with the following keys:\n\n- \"bias_score\": a float between 0.0 (no bias) and 1.0 (high bias),\n- \"bias_axes\": an array of strings identifying specific axes of bias (e.g., \"gender\", \"race\", \"socioeconomic status\"),\n- \"bias_explanation\": a brief explanation of any detected bias.\n\nIf bias is detected (i.e., bias_score > 0.0), also include:\n\n- \"debias_question\": a rewritten version of the question that mitigates the detected bias.\n\n**Question**: \"{question}\"\n\n**Instructions**:\n\n- Respond **only** with the JSON object in the exact format specified.\n- Do not include any additional text or commentary.\n- If no bias is detected, omit the \"debias_question\" field from the JSON object.\n\n**Example when bias is detected**:\n{{\n\"bias_score\": 0.8,\n\"bias_axes\": [\"gender\"],\n\"bias_explanation\": \"The question assumes that doctors are male.\",\n\"debias_question\": \"What steps should a doctor take to diagnose a patient?\"\n}}\n\n**Example when no bias is detected**:\n{{\n\"bias_score\": 0.0,\n\"bias_axes\": [],\n\"bias_explanation\": \"No bias detected in the question.\"\n}}"
  }
}
